{"nbformat_minor": 2, "cells": [{"source": "1\u00b0 PASO: Importamos m\u00f3dulos de apache spark", "cell_type": "markdown", "metadata": {}}, {"execution_count": 11, "cell_type": "code", "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.types import *", "outputs": [], "metadata": {}}, {"source": "2\u00b0 PASO: Creamos las session de apache spark en una variable", "cell_type": "markdown", "metadata": {}}, {"execution_count": 12, "cell_type": "code", "source": "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()", "outputs": [], "metadata": {}}, {"source": "3\u00b0 PASO: Verificamos la versi\u00f3n de apache spark", "cell_type": "markdown", "metadata": {}}, {"execution_count": 13, "cell_type": "code", "source": "\nspark", "outputs": [{"execution_count": 13, "output_type": "execute_result", "data": {"text/plain": "<pyspark.sql.session.SparkSession at 0x7f65e8263290>", "text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://cluster-f971-m.us-central1-f.c.exalted-cairn-300721.internal:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.3.4</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>PySparkShell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "}, "metadata": {}}], "metadata": {}}, {"source": "4\u00b0 PASO: Crear la estructura del dataframe", "cell_type": "markdown", "metadata": {}}, {"execution_count": 14, "cell_type": "code", "source": "df_schema = StructType([\nStructField(\"ID\", StringType(),True),\nStructField(\"NOMBRE\", StringType(),True),\nStructField(\"TELEFONO\", StringType(),True),\nStructField(\"CORREO\", StringType(),True),\nStructField(\"FECHA_INGRESO\", StringType(),True),\nStructField(\"EDAD\", IntegerType(),True),\nStructField(\"SALARIO\", DoubleType(),True),\nStructField(\"ID_EMPRESA\", StringType(),True),\n])", "outputs": [], "metadata": {}}, {"source": "5\u00b0 Definimos ruta del archivo\n", "cell_type": "markdown", "metadata": {}}, {"execution_count": 15, "cell_type": "code", "source": "#Archivo almacenado en hdfs\n#ruta_lectura = \"hdfs:/datalake/workload/persona.data\"\n\n#Archivo almacenado en storga - gcp\nruta_lectura = \"gs://course-bigdata-dev/datalake/workload/persona.data\"", "outputs": [], "metadata": {}}, {"source": "6\u00b0 Creamos el dataframe de Persona", "cell_type": "markdown", "metadata": {}}, {"execution_count": 16, "cell_type": "code", "source": "df_with_schema = spark.read.format(\"CSV\").option(\"header\",\"true\").option(\"delimiter\",\"|\").schema(df_schema).load(ruta_lectura)", "outputs": [], "metadata": {}}, {"execution_count": 17, "cell_type": "code", "source": "df_with_schema.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---+---------+--------------+--------------------+-------------+----+-------+----------+\n| ID|   NOMBRE|      TELEFONO|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA|\n+---+---------+--------------+--------------------+-------------+----+-------+----------+\n|  2|Priscilla|      155-2498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|\n|  3|  Jocelyn|1-204-956-8594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|\n|  4|    Aidan|1-719-862-9385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10|\n|  5|  Leandra|      839-8044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|\n|  6|     Bert|      797-4453|a.felis.ullamcorp...|   2017-04-25|  70| 7800.0|         7|\n|  7|     Mark|1-680-102-6792|Quisque.ac@placer...|   2006-04-21|  52| 8112.0|         5|\n|  8|    Jonah|      214-2975|eu.ultrices.sit@v...|   2017-10-07|  23|17040.0|         5|\n|  9|    Hanae|      935-2277|          eu@Nunc.ca|   2003-05-25|  69| 6834.0|         3|\n| 10|   Cadman|1-866-561-2701|orci.adipiscing.n...|   2001-05-19|  19| 7996.0|         7|\n| 11|  Melyssa|      596-7736|vel@vulputateposu...|   2008-10-14|  48| 4913.0|         8|\n| 12|   Tanner|1-739-776-7897|arcu.Aliquam.ultr...|   2011-05-10|  24|19943.0|         8|\n| 13|   Trevor|      512-1955|Nunc.quis.arcu@eg...|   2010-08-06|  34| 9501.0|         5|\n| 14|    Allen|      733-2795|felis.Donec@necle...|   2005-03-07|  59|16289.0|         2|\n| 15|    Wanda|      359-6973|Nam.nulla.magna@I...|   2005-08-21|  27| 1539.0|         5|\n| 16|    Alden|      341-8522|odio@morbitristiq...|   2006-12-05|  26| 3377.0|         2|\n| 17|     Omar|      720-1543|Phasellus.vitae.m...|   2014-06-24|  60| 6851.0|         6|\n| 18|     Owen|1-167-335-7541|     sociis@erat.com|   2002-04-09|  34| 4759.0|         7|\n| 19|    Laura|1-974-623-2057|    mollis@ornare.ca|   2017-03-09|  70|17403.0|         4|\n| 20|    Emery|1-672-840-0264|     at.nisi@vel.org|   2004-02-27|  24|18752.0|         9|\n| 21|  Carissa|1-300-877-0859|dignissim.pharetr...|   2011-10-16|  31| 1952.0|        10|\n+---+---------+--------------+--------------------+-------------+----+-------+----------+\nonly showing top 20 rows\n\n"}], "metadata": {}}, {"source": "8\u00b0 Definimos la ruta en hdfs donde almacenaremos el archiv", "cell_type": "markdown", "metadata": {}}, {"execution_count": 18, "cell_type": "code", "source": "ruta_destino = \"gs://course-bigdata-dev/datalake/landing/personas/\"", "outputs": [], "metadata": {}}, {"source": "9\u00b0 Guardamos el archivo en formato parquet", "cell_type": "markdown", "metadata": {}}, {"execution_count": 19, "cell_type": "code", "source": "df_with_schema.repartition(1).write.mode(\"overwrite\").format(\"parquet\").save(ruta_destino)", "outputs": [], "metadata": {}}, {"source": "-----------------------------------------------------------------------------------------\nCargando Empresas ", "cell_type": "markdown", "metadata": {}}, {"execution_count": 40, "cell_type": "code", "source": "\ndf_schema_empresa = StructType([\nStructField(\"ID\", StringType(),True),\nStructField(\"NOMBRE_EMPRESA\", StringType(),True)\n])", "outputs": [], "metadata": {}}, {"execution_count": 41, "cell_type": "code", "source": "ruta_empresa = \"gs://course-bigdata-dev/datalake/workload/empresa.data\"", "outputs": [], "metadata": {}}, {"execution_count": 42, "cell_type": "code", "source": "df_with_schema_empresa = spark.read.format(\"CSV\").option(\"header\",\"true\").option(\"delimiter\",\"|\").schema(df_schema_empresa).load(ruta_empresa)", "outputs": [], "metadata": {}}, {"execution_count": 43, "cell_type": "code", "source": "df_with_schema_empresa.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---+--------------+\n| ID|NOMBRE_EMPRESA|\n+---+--------------+\n|  2|     Microsoft|\n|  3|         Apple|\n|  4|        Toyota|\n|  5|        Amazon|\n|  6|        Google|\n|  7|       Samsung|\n|  8|            HP|\n|  9|           IBM|\n| 10|          Sony|\n+---+--------------+\n\n"}], "metadata": {}}, {"execution_count": 44, "cell_type": "code", "source": "ruta_destino_empresas = \"gs://course-bigdata-dev/datalake/landing/empresas/\"\n\ndf_with_schema_empresa.repartition(1).write.mode(\"overwrite\").format(\"parquet\").save(ruta_destino_empresas)", "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pyspark", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.14", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}